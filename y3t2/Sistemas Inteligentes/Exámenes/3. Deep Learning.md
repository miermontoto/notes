---
Temas:
- Concepto y objetivo
- Regresión lineal y representación
- Descenso del gradiente
- Funcionamiento general (!)
- Regresión y clasificación binaria
---

## Concepto y objetivo
El Deep Learning es una rama del aprendizaje automático (machine learning) que se centra en el entrenamiento de redes neuronales profundas para aprender y representar patrones complejos en los datos. El objetivo principal del Deep Learning es desarrollar modelos que puedan aprender automáticamente características y representaciones de alto nivel a partir de datos no etiquetados o etiquetados de forma débil.

El problema de Machine Learning y por lo que nace Deep Learning es evitar la necesidad de que una persona se encargue de la extracción de características de la información. Al eliminar la "manualidad" de la ecuación, reduciendo la tasa de fallos cometidos.

El objetivo funcional de Deep Learning es encontrar la función no linear con la mayor consistencia de datos posible. Consistente, en este contexto, significa que se puedan hacer estimaciones de manera sencilla de la función a partir de algunas transformaciones de manera que estas estimaciones minimicen una función de pérdida, que es la inconsistencia.

De manera matemática, lo que se busca es resolver la optimización de una función tal que: $$\theta\leftarrow argmin_{\theta}{1\over|D|}\sum_{(x,y)\in D}loss(y,f_\theta (x))$$


## Regresión lineal y representación
La manera de representar la información es muy relevante para este tipo de problemas - como por ejemplo la representación en coordenadas polares y cartesianas. 

¿Por qué hacerlo todo de manera no-lineal? Aunque las funciones de pérdida son irresolubles, pero compensa porque la inconsistencia obtenida es muy buena, mejor que en humanos.

Se aplica un algoritmo, normalmente ReLU, para hacer la función no lineal.

## Descenso del gradiente
El descenso del gradiente es un algoritmo utilizado en Deep Learning para entrenar redes neuronales y ajustar los pesos de las conexiones entre las neuronas. El objetivo es minimizar una función de pérdida que mide la diferencia entre las predicciones del modelo y los valores reales. El descenso del gradiente utiliza la derivada de la función de pérdida con respecto a los pesos de la red para actualizar gradualmente los pesos en la dirección que reduce la pérdida. El proceso se repite iterativamente hasta que se alcanza un mínimo o se cumple un criterio de parada.

## Funcionamiento general


## Regresión y clasificación binaria

## Final remarks
