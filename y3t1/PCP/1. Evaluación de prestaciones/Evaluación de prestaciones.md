# Evaluaci√≥n de prestaciones

## Antecedentes
- **Tiempo de Ejeuci√≥n Secuencial:** tiempo que tarda en ejeuctarse el programa en una sola unidad de proceso.
	- El an√°lisis se hace en [[#FLOPs]] (operaciones flotantes por segundo).
>[!ERROR]- No relevante
>No es importante para el an√°lisis, es m√°s importante el tiempo de ejec. paralelo.

- La medici√≥n del **rendimiento** de un problema se realiza utilizando solo el tama√±o del problema y el n√∫mero de procesadores.
- Se tienen en cuenta mediciones emp√≠ricas, en combinaciones con el modelo te√≥rico.

### Par√°metros absolutos
- Representan el coste real de los algoritmos.
- Importantes en problemas de tiempo real.
- No permiten conocer el comportamiento del algoritmo.
***- ej: tiempo de ejecuci√≥n.***

### Par√°metros relativos
- Se obtienen de los par√°metros absolutos.
- Permiten comparar algoritmos entre s√≠.
- Estiman la efectividad con la que los algoritmos utilizan los recursos.
***- ej: coste, overhead, eficiencia, speedup y escabilidad.***

---

## Tiempo de Ejecuci√≥n Paralelo
<mark style="background: #ADCCFFA6;">Tiempo transcurrido desde que empieza el primer procesador hasta que termina el √∫ltimo.</mark> 

**T<sub>sol</sub>(n, p):** tiempo de solapamiento entre T<sub>ar</sub> y T<sub>co</sub>.
**T<sub>ov</sub>(n, p):** tiempo de sobrecarga (esperas, creaci√≥n de procesos, etc)

T<sub>sol</sub> y T<sub>ov</sub> son dif√≠ciles de estimar.

### T<sub>ar</sub>
<mark style="background: #ADCCFFA6;">Tiempo que el algoritmo emplea realizando el c√°lculo.</mark> 
- Se expresa en flop (en segundos en el modelo emp√≠rico).
- Se estima te√≥ricamente como $$ T_{ar}(n,p) = nt_c$$ siendo *n* el n√∫mero de flop y *t<sub>c</sub>* el tiempo por flop.

### T<sub>co</sub>
<mark style="background: #ADCCFFA6;">Tiempo que el algoritmo emplea enviando mensajes o en operaciones de sincronizaci√≥n.</mark> 
- Se usa el mismo modelo para comunicaciones externas e internas.
- Se usa el mismo modelo para memoria compartida o memoria distribuida.
- El intercambio de informaci√≥n entre dos procesos o procesadores vecinos (P2P) se estima con: $$T_{co}(n,p) = t_s + nt_w$$
	donde t<sub>s</sub> es la latencia (startup time) y t<sub>w</sub> el ancho de banda.
- La latencia suele ser mucho mayor que el ancho de banda, por lo que es mejor enviar una sola comunicaci√≥n a varias vecinos que hacer varias comunicaciones a un vecino cada una.
- En memoria compartida, se supone que la sincronizaci√≥n es un mensaje de tama√±o 1 (n=1).

### Flop
<mark style="background: #ADCCFFA6;">Coste de una operaci√≥n b√°sica en coma flotante (suma, resta, multiplicaci√≥n, divisi√≥n).</mark> 
- El coste de otras operaciones se expresan en t√©rmino de su n√∫mero de flop.
- En este tipo de enfoques el resto de operaciones (arim√©trica entera, ...) no se suelen contablizar.

#### FLOPs
<mark style="background: #ADCCFFA6;">N√∫mero de flops por segundo.</mark> 
- Es una velocidad.
- **TPP<sub>dp</sub>** o *Theoretical Peak double precision* se expresa en GFLOPs. Es una estimaci√≥n optimista: $$ TPP_{dp} = chasis \times nodos_{chasis} \times sockets_{nodo} \times cores_{socket} \times clock_{GHz} \times (\frac{n¬∫ flop}{ciclo})^{**}$$ $$ TPP_{dp} = sockets \times cores_{socket} \times clock_{GHz} \times (AVX|FMA)^*$$
	\*\*4x, 8x, 16x, seg√∫n el procesador
	\* spec.org u otras fuentes para obtener la tecnolog√≠a del procesador

---

## Coste y sobrecarga

### Coste
$$C(n,p) = pT(n,p)$$
- Un algoritmo es de coste √≥ptimo si C es proporcional a T.

### Sobrecarga / Overhead
<mark style="background: #ADCCFFA6;">Expresa el coste a√±adido con respecto al algoritmo secuencial, es decir, el tiempo extra que los procesadores colectivamente consumen respecto al tiempo del algoritmo secuencial √≥ptimo.</mark> 
$$T_0(n,p) = C(n,p) - T(n)$$
---

## Speedup y Eficiencia
### Speedup
<mark style="background: #ADCCFFA6;">Expresa la ganancia de velocidad del paralelo al secuencial.</mark> 
$$S(n,p) = \frac{T(n)}{T(n,p)}$$
- Todo algoritmo paralelo se puede simular en una m√°quina secuencial ejecutando en serie los pasos paralelos. **Por lo tanto, S(n,p) est√° acotada por:** $$T(n,1) \leq pT(n,p) ‚Üí 0 \leq S(n,p) \leq p$$
- Si vale *p*, **speedup lineal**. La carga est√° balanceada, las comunicaciones no penalizan, perfecto.
- Si vale menos que *p*, **speedup sublineal.** Hay dependencia de datos, no siempre es posible dividir el problema en p subproblemas concurrentes...
- Si vale m√°s que *p*, **speedup superlienal.** El algoritmo secuencial no es √≥ptimo, se ha incurrido en un error de c√°lculo o hay efectos colaterales(cach√©...)

### Eficiencia
<mark style="background: #ADCCFFA6;">El speedup partido por p, para que se acote entre 0 y 1.</mark> $$0 \leq E(n,p) = \frac{S(n,p)}{p} \leq 1$$
### [[Ejemplos y ejercicios]]

## Modelos de rendimiento
### Ley de Amdahl
- Mide el incremento de velocidad m√°ximo de los algoritmos paralelos (speedup).
- El tiempo de ejecuci√≥n de un algoritmo se expresa como $$t(n) = \alpha(n) + \beta(n)$$ donde …ë(n) es el tiempo de la parte secuencial, no paralelizable y Œ≤(n) es el tiempo de la parte paralelizable.
- El tiempo paralelo se puede definir como $$t(n,p) = \alpha(n) + \frac{\beta(n)}{p}$$

Sea …ë(n) + Œ≤(n) = 1, entonces $$S(n,p) = \frac{T(n)}{T(n,p)} = \frac{p}{(p-1)\alpha(n)+1} \leq \frac{1}{\alpha(n)} $$

Aplicando esto, si el algoritmo es: 
	- paralelizable en un 90%: $$S(n,p) = \frac{p}{(p-1)0.1 + 1} \lt \frac{1}{0.1} = 10$$
	- paralelizable en un 50%: $$S(n,p) = \frac{p}{(p-1)0.5 + 1} \lt \frac{1}{0.5} = 2$$
![[_resources/Pasted image 20220915125305.png]]

Haciendo manipulaciones algebr√°icas: $$S(n,p) = \frac{1}{(1-FP)+\frac{PF}{p}}$$donde PF es el % de fracci√≥n paralela (en tanto por uno).
Se define como **rendimiento efectivo** (RE) de un algoritmo paralelo como:
$$RE_{dp}=\frac{1}{(1-PF)+\frac{PF}{p}}\times clock_{GHz}\times (AVX|FMA)$$
$$RE_{dp}=\frac{1}{(1-PF)+\frac{PF}{p}}\times clock_{GHz}\times\frac{n¬∫flop}{ciclo}$$

### Resumen
- La eficiencia decrece mon√≥tonamente al aumentar el n√∫mero de procesadores y mantener constante el tama√±o del problema.
- El tiempo de ejecuci√≥n puede aumentar al crecer el valor de *p*.
- No es productivo usar m√°s procesadores que una cantidad determinadad para un problema fijo.
- Los conceptos de speedup y eficiencia permiten conocer la mejora y el grado de aprovechamiento que un algoritmo paralelo hace de una determinada configuraci√≥n.
- No obstante, ambos par√°metros son dependientes de *n* y *p*. Las conclusiones pueden no ser las mismas cuando algunos de estos par√°metros cambie, es decir, cuando escala *n* junto a *p*.

## Modelos de Isorendimiento
<mark style="background: #ADCCFFA6;">Muestran c√≥mo se adapta el algoritmo cuando crecen <i>n</i> y <i>p</i>.</mark>

### Funci√≥n de Isotiemo
**M√©trica/prestaciones:** tiempo.
**Recursos:** n√∫mero de procesadores.

### Funci√≥n de Isoeficiencia
**M√©trica/prestaciones:** eficiencia.
**Recursos:** n√∫mero de procesadores.

¬øC√≥mo debe crecer el tama√±o del problema (œâ) en funci√≥n de p para mantener la eficiencia constante?

#### Algoritmo Escalable
<mark style="background: #ADCCFFA6;">Aquel cuya funci√≥n de isoeficiencia es lineal respecto al n√∫mero de procesadores.</mark>

### Escalabilidad
#### Procedimiento de c√°lculo #1:
- Fijar la eficiencia a un valor deseado y despejar la carga computacional œâ.
- A menor aumento de œâ al aumentar *p*, mayor escalabilidad.


##### <mark style="background: #BBFABBA6;">Ejemplo</mark>
![[_resources/Pasted image 20220920092201.png|1050]]
![[_resources/Pasted image 20220920092245.png|1050]]

#### Procedimiento de c√°lculo #2:
![[_resources/Pasted image 20220920092539.png|1050]]


##### <mark style="background: #BBFABBA6;">Ejercicios</mark>
![[_resources/Evaluaci√≥n de prestaciones 2022-09-20 09.44.21.excalidraw]]
![[_resources/Evaluaci√≥n de prestaciones 2022-09-20 09.54.24.excalidraw]]

### Eficiencia escalable
Como el objetivo es mantener la eficiencia constante, se hacen crecer a las dos variables en la misma proporci√≥n.
Si la eficiencia es constante, esacala. $$E_{scl}(W,r) = \frac{T_{paralelo}(W,1)}{T_{paralelo}(rW,r)} o \frac{T(W)}{T_{paralelo}(rW,r)}$$
Es buena estrategia multiplicar por dos.

## Sistemas h√≠bridos / heterog√©neos
<mark style="background: #ADCCFFA6;">Sistemas confirmados por √≠tems de distinta naturaleza.</mark>
Cada √≠tem tiene su propia constante.

#### <mark style="background: #BBFABBA6;">Ejemplo</mark>
Sea un cl√∫ster con ùëù ordenadores iguales conectados a una red, con Tùë† la constante de establecimiento y Tùë§
la inversa del ancho de banda. Cada ordenador tiene una CPU con ùëò n√∫cleos, con Tùëê la constante de c√°lculo.
Cada ordenador tiene la misma GPU de apoyo, siendo Tùëê<sub>FPU</sub> , Tùë†<sub>GPU</sub> y Tùë§<sub>GPU</sub> las constantes de c√°lculo y de
comunicaciones CPU/GPU, respectivamente. La GPU es 9x m√°s potente que la CPU. Sea Tùëõ = ùëõ<sup>2</sup>Tùëê y un
dise√±o paralelo sin dependencias externas donde todos los elementos realizan la misma computaci√≥n. Se
pide: 
	A) tiempo de ejecuci√≥n paralelo de cada ordenador
	B) tiempo de ejecuci√≥n del sistema si el coste de las comunicaciones CPU/GPU es 0
	C) an√°lisis de la Escalabilidad y Eficiencia Escalada desde b).

Se env√≠a y se recibe la misma cantidad de datos de la GPU, no hay dependencias externas y reparto balanceado de tiempo de c√°lculo entre CPU y GPU.<sup>*</sup>

![[_resources/Evaluaci√≥n de prestaciones 2022-09-20 10.12.07.excalidraw]]
